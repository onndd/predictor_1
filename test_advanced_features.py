#!/usr/bin/env python3
"""
GeliÅŸmiÅŸ Ä°statistiksel Ã–zellikler Test Sistemi
==============================================

Bu script geliÅŸmiÅŸ istatistiksel Ã¶zelliklerin:
1. DÃ¼zgÃ¼n Ã§alÄ±ÅŸÄ±p Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ±
2. Mevcut modellerle uyumlu olup olmadÄ±ÄŸÄ±nÄ±
3. Performans etkisini
test eder.
"""

import sys
import os
import numpy as np
import pandas as pd
from typing import List, Dict, Any
import time

# Add src to path
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

try:
    from feature_engineering.advanced_statistical_features import (
        AdvancedStatisticalFeatures,
        extract_advanced_statistical_features
    )
    from feature_engineering.unified_extractor import UnifiedFeatureExtractor
    print("âœ… Temel modÃ¼ller baÅŸarÄ±yla import edildi")
    
    # DataLoader optional import
    try:
        from data_processing.loader import DataLoader
        DATA_LOADER_AVAILABLE = True
        print("âœ… DataLoader da mevcut")
    except ImportError as e:
        DATA_LOADER_AVAILABLE = False
        print(f"âš ï¸ DataLoader import hatasÄ±: {e}")
        print("DataLoader olmadan test devam edecek")
        
except ImportError as e:
    print(f"âŒ Kritik import hatasÄ±: {e}")
    sys.exit(1)

def generate_test_data(n_samples: int = 1000) -> List[float]:
    """Test verisi Ã¼retir"""
    np.random.seed(42)
    
    # KarmaÅŸÄ±k finansal zaman serisi benzeri veri
    trends = np.cumsum(np.random.randn(n_samples) * 0.01)
    volatility = np.random.gamma(2, 0.5, n_samples)
    noise = np.random.randn(n_samples) * 0.1
    
    # Rejim deÄŸiÅŸiklikleri ekle
    regime_changes = [300, 600, 800]
    for change_point in regime_changes:
        if change_point < n_samples:
            trends[change_point:] += np.random.choice([-1, 1]) * 0.5
    
    # JetX benzeri deÄŸerler (1.0 - 10.0 arasÄ±)
    base_values = 1.0 + 9.0 * (1 / (1 + np.exp(-(trends + volatility + noise))))
    
    # Anomaliler ekle
    anomaly_indices = np.random.choice(n_samples, size=n_samples//50, replace=False)
    base_values[anomaly_indices] *= np.random.uniform(0.1, 5.0, len(anomaly_indices))
    
    return base_values.tolist()

def test_advanced_features_basic():
    """Temel geliÅŸmiÅŸ Ã¶zellik testleri"""
    print("\nğŸ”¬ Temel GeliÅŸmiÅŸ Ã–zellik Testleri")
    print("=" * 50)
    
    # Test verisi oluÅŸtur
    test_data = generate_test_data(500)
    print(f"Test verisi oluÅŸturuldu: {len(test_data)} sample")
    
    # Advanced features sÄ±nÄ±fÄ±nÄ± test et
    extractor = AdvancedStatisticalFeatures([10, 20, 50])
    
    try:
        # Hurst exponent testi
        start_time = time.time()
        hurst = extractor.compute_hurst_exponent(np.array(test_data))
        hurst_time = time.time() - start_time
        print(f"âœ… Hurst Exponent: {hurst:.4f} (SÃ¼re: {hurst_time:.2f}s)")
        
        # Fractal dimension testi
        start_time = time.time()
        fractal_features = extractor.compute_fractal_dimension(np.array(test_data))
        fractal_time = time.time() - start_time
        print(f"âœ… Fractal Dimensions: {fractal_features} (SÃ¼re: {fractal_time:.2f}s)")
        
        # RQA testi
        start_time = time.time()
        rqa_features = extractor.compute_rqa_features(np.array(test_data))
        rqa_time = time.time() - start_time
        print(f"âœ… RQA Features: {list(rqa_features.keys())} (SÃ¼re: {rqa_time:.2f}s)")
        
        # Entropy testi
        start_time = time.time()
        entropy_features = extractor.compute_entropy_features(np.array(test_data))
        entropy_time = time.time() - start_time
        print(f"âœ… Entropy Features: {list(entropy_features.keys())} (SÃ¼re: {entropy_time:.2f}s)")
        
        # Rejim deÄŸiÅŸiklik testi
        start_time = time.time()
        regime_features = extractor.compute_regime_change_indicators(np.array(test_data))
        regime_time = time.time() - start_time
        print(f"âœ… Regime Change Features: {list(regime_features.keys())} (SÃ¼re: {regime_time:.2f}s)")
        
        return True
        
    except Exception as e:
        print(f"âŒ Temel test hatasÄ±: {e}")
        return False

def test_advanced_features_extraction():
    """Ana Ã§Ä±karÄ±m fonksiyonu testi"""
    print("\nğŸ”§ GeliÅŸmiÅŸ Ã–zellik Ã‡Ä±karÄ±m Testi")
    print("=" * 50)
    
    test_data = generate_test_data(200)
    
    try:
        start_time = time.time()
        feature_matrix = extract_advanced_statistical_features(
            test_data, 
            window_sizes=[10, 20, 50]
        )
        extraction_time = time.time() - start_time
        
        print(f"âœ… Feature matrix oluÅŸturuldu: {feature_matrix.shape}")
        print(f"   - {feature_matrix.shape[0]} sample")
        print(f"   - {feature_matrix.shape[1]} Ã¶zellik")
        print(f"   - SÃ¼re: {extraction_time:.2f}s")
        
        # NaN/Inf kontrolÃ¼
        nan_count = np.isnan(feature_matrix).sum()
        inf_count = np.isinf(feature_matrix).sum()
        print(f"   - NaN sayÄ±sÄ±: {nan_count}")
        print(f"   - Inf sayÄ±sÄ±: {inf_count}")
        
        if nan_count == 0 and inf_count == 0:
            print("âœ… Temiz feature matrix (NaN/Inf yok)")
        else:
            print("âš ï¸ Feature matrix'te NaN/Inf deÄŸerler var")
            
        return True
        
    except Exception as e:
        print(f"âŒ Ã‡Ä±karÄ±m test hatasÄ±: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_unified_extractor_integration():
    """Unified extractor entegrasyonu testi"""
    print("\nğŸ”— Unified Extractor Entegrasyon Testi")
    print("=" * 50)
    
    test_data = generate_test_data(300)
    
    try:
        # Unified extractor oluÅŸtur
        extractor = UnifiedFeatureExtractor(
            feature_windows=[5, 10, 20],
            lag_windows=[5, 10],
            lags=[1, 2, 3],
            model_sequence_length=10
        )
        
        print("Unified extractor oluÅŸturuldu")
        
        # Fit
        start_time = time.time()
        extractor.fit(test_data)
        fit_time = time.time() - start_time
        print(f"âœ… Fit tamamlandÄ± (SÃ¼re: {fit_time:.2f}s)")
        
        # Transform
        start_time = time.time()
        feature_matrix = extractor.transform(test_data)
        transform_time = time.time() - start_time
        
        print(f"âœ… Transform tamamlandÄ±:")
        print(f"   - Shape: {feature_matrix.shape}")
        print(f"   - SÃ¼re: {transform_time:.2f}s")
        
        # Feature names kontrol
        feature_names = extractor.get_feature_names()
        print(f"   - Total feature sayÄ±sÄ±: {len(feature_names)}")
        
        # GeliÅŸmiÅŸ Ã¶zellik sayÄ±sÄ±nÄ± kontrol et
        advanced_feature_count = sum(1 for name in feature_names if any(
            keyword in name for keyword in [
                'hurst_', 'higuchi_', 'katz_', 'petrosian_',
                'shannon_', 'approximate_', 'sample_', 'permutation_', 'spectral_',
                'rqa_', 'cusum_', 'variance_ratio', 'trend_change', 'recent_change'
            ]
        ))
        print(f"   - GeliÅŸmiÅŸ Ã¶zellik sayÄ±sÄ±: {advanced_feature_count}")
        
        # NaN/Inf kontrolÃ¼
        nan_count = np.isnan(feature_matrix).sum()
        inf_count = np.isinf(feature_matrix).sum()
        print(f"   - NaN: {nan_count}, Inf: {inf_count}")
        
        if nan_count == 0 and inf_count == 0:
            print("âœ… Entegrasyon baÅŸarÄ±lÄ±!")
            return True, feature_matrix, feature_names
        else:
            print("âš ï¸ NaN/Inf deÄŸerler tespit edildi")
            return False, None, None
            
    except Exception as e:
        print(f"âŒ Entegrasyon test hatasÄ±: {e}")
        import traceback
        traceback.print_exc()
        return False, None, None

def test_performance_comparison():
    """Performans karÅŸÄ±laÅŸtÄ±rmasÄ±"""
    print("\nâš¡ Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±")
    print("=" * 50)
    
    test_sizes = [100, 200, 500]
    
    for size in test_sizes:
        print(f"\nTest boyutu: {size} sample")
        test_data = generate_test_data(size)
        
        # Sadece temel Ã¶zellikler
        try:
            from feature_engineering.statistical_features import extract_statistical_features
            
            start_time = time.time()
            basic_features = extract_statistical_features(
                test_data,
                feature_windows=[5, 10, 20],
                lag_windows=[5, 10],
                lags=[1, 2, 3]
            )
            basic_time = time.time() - start_time
            
            print(f"  ğŸ“Š Temel Ã¶zellikler: {basic_features.shape[1]} Ã¶zellik, {basic_time:.3f}s")
            
        except Exception as e:
            print(f"  âŒ Temel Ã¶zellik hatasÄ±: {e}")
            basic_time = float('inf')
        
        # GeliÅŸmiÅŸ Ã¶zellikler
        try:
            start_time = time.time()
            advanced_features = extract_advanced_statistical_features(
                test_data,
                window_sizes=[5, 10, 20]
            )
            advanced_time = time.time() - start_time
            
            print(f"  ğŸ§  GeliÅŸmiÅŸ Ã¶zellikler: {advanced_features.shape[1]} Ã¶zellik, {advanced_time:.3f}s")
            
            if basic_time != float('inf'):
                ratio = advanced_time / basic_time
                print(f"  âš–ï¸ SÃ¼re oranÄ± (geliÅŸmiÅŸ/temel): {ratio:.2f}x")
            
        except Exception as e:
            print(f"  âŒ GeliÅŸmiÅŸ Ã¶zellik hatasÄ±: {e}")

def test_real_data_compatibility():
    """GerÃ§ek veri uyumluluÄŸu testi"""
    print("\nğŸ“‹ GerÃ§ek Veri UyumluluÄŸu Testi")
    print("=" * 50)
    
    if not DATA_LOADER_AVAILABLE:
        print("âš ï¸ DataLoader mevcut deÄŸil, simÃ¼lasyon verisi kullanÄ±lÄ±yor")
        return test_unified_extractor_integration()[0]
    
    try:
        # Mevcut data loader ile test
        data_loader = DataLoader()
        
        # Cache'den veri yÃ¼kle (varsa)
        cache_file = "data/cache/jetx_data_full_data.pkl"
        if os.path.exists(cache_file):
            print("Cache dosyasÄ± bulundu, yÃ¼kleniyor...")
            import pickle
            with open(cache_file, 'rb') as f:
                real_data = pickle.load(f)
            
            if isinstance(real_data, list) and len(real_data) > 100:
                test_data = real_data[:500]  # Ä°lk 500 sample al
                print(f"GerÃ§ek veri yÃ¼klendi: {len(test_data)} sample")
                
                # Unified extractor ile test
                extractor = UnifiedFeatureExtractor(
                    feature_windows=[10, 20, 50],
                    lag_windows=[10, 20],
                    lags=[1, 2, 3, 5],
                    model_sequence_length=20
                )
                
                start_time = time.time()
                extractor.fit(test_data)
                feature_matrix = extractor.transform(test_data)
                total_time = time.time() - start_time
                
                print(f"âœ… GerÃ§ek veri iÅŸleme baÅŸarÄ±lÄ±:")
                print(f"   - Feature matrix: {feature_matrix.shape}")
                print(f"   - Toplam sÃ¼re: {total_time:.2f}s")
                print(f"   - Sample baÅŸÄ±na sÃ¼re: {total_time/len(test_data)*1000:.2f}ms")
                
                return True
                
        print("âš ï¸ Cache dosyasÄ± bulunamadÄ±, simÃ¼lasyon verisi kullanÄ±lÄ±yor")
        return test_unified_extractor_integration()[0]
        
    except Exception as e:
        print(f"âŒ GerÃ§ek veri test hatasÄ±: {e}")
        return False

def main():
    """Ana test fonksiyonu"""
    print("ğŸš€ GeliÅŸmiÅŸ Ä°statistiksel Ã–zellikler Test BaÅŸlatÄ±lÄ±yor")
    print("=" * 60)
    
    results = {}
    
    # 1. Temel testler
    results['basic'] = test_advanced_features_basic()
    
    # 2. Ã–zellik Ã§Ä±karÄ±m testi
    results['extraction'] = test_advanced_features_extraction()
    
    # 3. Entegrasyon testi
    results['integration'], feature_matrix, feature_names = test_unified_extractor_integration()
    
    # 4. Performans testi
    test_performance_comparison()
    
    # 5. GerÃ§ek veri uyumluluÄŸu
    results['real_data'] = test_real_data_compatibility()
    
    # SonuÃ§larÄ± Ã¶zetle
    print("\nğŸ“‹ TEST SONUÃ‡LARI")
    print("=" * 60)
    
    for test_name, result in results.items():
        status = "âœ… BAÅARILI" if result else "âŒ BAÅARISIZ"
        print(f"{test_name.upper():20} : {status}")
    
    all_passed = all(results.values())
    
    if all_passed:
        print("\nğŸ‰ TÃœM TESTLER BAÅARILI!")
        print("GeliÅŸmiÅŸ istatistiksel Ã¶zellikler sisteme baÅŸarÄ±yla entegre edildi.")
        
        if feature_names:
            print(f"\nToplam Ã¶zellik sayÄ±sÄ±: {len(feature_names)}")
            
            # Ã–zellik kategorilerini say
            categories = {
                'Temel Ä°statistik': len([n for n in feature_names if n.startswith('stat_')]),
                'Hurst Exponent': len([n for n in feature_names if 'hurst_' in n]),
                'Fractal Dimension': len([n for n in feature_names if any(x in n for x in ['higuchi_', 'katz_', 'petrosian_'])]),
                'Entropy': len([n for n in feature_names if any(x in n for x in ['shannon_', 'approximate_', 'sample_', 'permutation_', 'spectral_'])]),
                'RQA': len([n for n in feature_names if 'rqa_' in n]),
                'Rejim DeÄŸiÅŸiklik': len([n for n in feature_names if any(x in n for x in ['cusum_', 'variance_ratio', 'trend_change', 'recent_change'])]),
                'Kategorik': len([n for n in feature_names if n.startswith('cat_')]),
                'Pattern': len([n for n in feature_names if n.startswith('ngram_')]),
                'Benzerlik': len([n for n in feature_names if n.startswith('sim_')])
            }
            
            print("\nÃ–zellik kategorileri:")
            for category, count in categories.items():
                print(f"  {category:20}: {count:3d} Ã¶zellik")
                
    else:
        print("\nâŒ BAZI TESTLER BAÅARISIZ!")
        print("LÃ¼tfen hatalarÄ± gÃ¶zden geÃ§irin ve dÃ¼zeltin.")
    
    return all_passed

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
