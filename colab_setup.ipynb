{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_header"
      },
      "source": [
        "# ğŸš€ Predictor_1 Google Colab Setup\n",
        "\n",
        "Bu notebook, JetX Predictor_1 projesini Google Colab'da Ã§alÄ±ÅŸtÄ±rmak iÃ§in gerekli kurulumlarÄ± yapar.\n",
        "\n",
        "## ğŸ“‹ Kurulum AdÄ±mlarÄ±:\n",
        "1. **GPU KontrolÃ¼** - CUDA desteÄŸi kontrol\n",
        "2. **Proje Klonlama** - GitHub'dan projeyi indir\n",
        "3. **Dependencies** - Gerekli kÃ¼tÃ¼phaneleri yÃ¼kle\n",
        "4. **Test** - Sistem testleri Ã§alÄ±ÅŸtÄ±r\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpu_check"
      },
      "outputs": [],
      "source": [
        "# ğŸ” GPU ve Sistem KontrolÃ¼\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "import os\n",
        "\n",
        "print(\"ğŸ” SYSTEM CHECK\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Python: {sys.version}\")\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"TensorFlow: {tf.__version__}\")\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "else:\n",
        "    print(\"âš ï¸ GPU not available. Using CPU only.\")\n",
        "    print(\"ğŸ’¡ Runtime > Change runtime type > GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clone_repo"
      },
      "outputs": [],
      "source": [
        "# ğŸ“¥ GitHub Repository Klonlama\n",
        "import os\n",
        "\n",
        "# EÄŸer zaten klonlanmÄ±ÅŸsa, gÃ¼ncelle\n",
        "if os.path.exists('/content/predictor_1'):\n",
        "    print(\"ğŸ“ Proje zaten mevcut. GÃ¼ncelleniyor...\")\n",
        "    %cd /content/predictor_1\n",
        "    !git pull origin main\n",
        "else:\n",
        "    print(\"ğŸ“¥ GitHub'dan proje klonlanÄ±yor...\")\n",
        "    %cd /content\n",
        "    !git clone https://github.com/onndd/predictor_1.git\n",
        "    %cd predictor_1\n",
        "\n",
        "print(\"âœ… Proje hazÄ±r!\")\n",
        "print(f\"ğŸ“‚ Ã‡alÄ±ÅŸma dizini: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_deps"
      },
      "outputs": [],
      "source": [
        "# ğŸ“¦ Dependencies YÃ¼kleme\n",
        "print(\"ğŸ“¦ DEPENDENCIES YÃœKLEME\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Ã–nce requirements dosyasÄ±nÄ± kontrol et\n",
        "!ls -la *.txt\n",
        "\n",
        "# Enhanced requirements yÃ¼kle\n",
        "print(\"\\nğŸ“¥ Enhanced dependencies yÃ¼kleniyor...\")\n",
        "!pip install -r requirements_enhanced.txt\n",
        "\n",
        "# Ek PyTorch ve ML kÃ¼tÃ¼phaneleri\n",
        "print(\"\\nğŸ”§ Ek ML kÃ¼tÃ¼phaneleri...\")\n",
        "!pip install fastdtw\n",
        "!pip install optuna\n",
        "!pip install plotly\n",
        "!pip install seaborn\n",
        "\n",
        "print(\"\\nâœ… TÃ¼m dependencies yÃ¼klendi!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup_paths"
      },
      "outputs": [],
      "source": [
        "# ğŸ”§ Python Path Kurulumu\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Proje dizinini Python path'e ekle\n",
        "project_root = '/content/predictor_1'\n",
        "src_path = os.path.join(project_root, 'src')\n",
        "\n",
        "if src_path not in sys.path:\n",
        "    sys.path.insert(0, src_path)\n",
        "    print(f\"âœ… {src_path} Python path'e eklendi\")\n",
        "\n",
        "# Dizin yapÄ±sÄ±nÄ± kontrol et\n",
        "print(\"\\nğŸ“ PROJE YAPISINI KONTROL ET\")\n",
        "print(\"=\" * 40)\n",
        "for root, dirs, files in os.walk('src'):\n",
        "    level = root.replace('src', '').count(os.sep)\n",
        "    indent = ' ' * 2 * level\n",
        "    print(f\"{indent}{os.path.basename(root)}/\")\n",
        "    subindent = ' ' * 2 * (level + 1)\n",
        "    for file in files[:3]:  # Ä°lk 3 dosyayÄ± gÃ¶ster\n",
        "        if file.endswith('.py'):\n",
        "            print(f\"{subindent}{file}\")\n",
        "    if len(files) > 3:\n",
        "        print(f\"{subindent}... ({len(files)-3} more files)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test_imports"
      },
      "outputs": [],
      "source": [
        "# ğŸ§ª Import Testleri\n",
        "print(\"ğŸ§ª IMPORT TESTLERI\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Test import'larÄ±\n",
        "try:\n",
        "    from data_processing.loader import load_data_from_sqlite\n",
        "    print(\"âœ… Data Processing: loader\")\n",
        "except ImportError as e:\n",
        "    print(f\"âŒ Data Processing loader: {e}\")\n",
        "\n",
        "try:\n",
        "    from data_processing.transformer import transform_to_categories\n",
        "    print(\"âœ… Data Processing: transformer\")\n",
        "except ImportError as e:\n",
        "    print(f\"âŒ Data Processing transformer: {e}\")\n",
        "\n",
        "try:\n",
        "    from models.deep_learning.n_beats.n_beats_model import NBeatsPredictor\n",
        "    print(\"âœ… Models: N-Beats\")\n",
        "except ImportError as e:\n",
        "    print(f\"âŒ N-Beats model: {e}\")\n",
        "\n",
        "try:\n",
        "    from models.deep_learning.tft.tft_model import TFTPredictor\n",
        "    print(\"âœ… Models: TFT\")\n",
        "except ImportError as e:\n",
        "    print(f\"âŒ TFT model: {e}\")\n",
        "\n",
        "try:\n",
        "    from models.sequential.lstm_model import ModernLSTMModel\n",
        "    print(\"âœ… Models: LSTM\")\n",
        "except ImportError as e:\n",
        "    print(f\"âŒ LSTM model: {e}\")\n",
        "\n",
        "try:\n",
        "    from models.ml_models import RandomForestJetXPredictor\n",
        "    print(\"âœ… Models: Random Forest\")\n",
        "except ImportError as e:\n",
        "    print(f\"âŒ Random Forest: {e}\")\n",
        "\n",
        "print(\"\\nğŸ¯ Import testleri tamamlandÄ±!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_system_test"
      },
      "outputs": [],
      "source": [
        "# ğŸ” Sistem Testleri\n",
        "print(\"ğŸ” SISTEM TESTLERI\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Data processing testini Ã§alÄ±ÅŸtÄ±r\n",
        "print(\"ğŸ“Š Data Processing testi Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor...\")\n",
        "!python3 test_data_processing.py\n",
        "\n",
        "print(\"\\nğŸ‰ Sistem testleri tamamlandÄ±!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_sample_data"
      },
      "outputs": [],
      "source": [
        "# ğŸ“Š Ã–rnek JetX Verisi OluÅŸturma\n",
        "import numpy as np\n",
        "import sqlite3\n",
        "from data_processing.loader import save_result_to_sqlite\n",
        "\n",
        "print(\"ğŸ“Š Ã–RNEK JETX VERÄ°SÄ° OLUÅTURMA\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# GerÃ§ekÃ§i JetX verisi simÃ¼lasyonu\n",
        "np.random.seed(42)\n",
        "sample_data = []\n",
        "\n",
        "for i in range(1000):\n",
        "    # JetX daÄŸÄ±lÄ±mÄ±nÄ± simÃ¼le et\n",
        "    rand = np.random.random()\n",
        "    \n",
        "    if rand < 0.25:  # %25 crash (1.0-1.5)\n",
        "        value = np.random.uniform(1.0, 1.49)\n",
        "    elif rand < 0.45:  # %20 dÃ¼ÅŸÃ¼k (1.5-2.5)\n",
        "        value = np.random.uniform(1.5, 2.5)\n",
        "    elif rand < 0.70:  # %25 orta (2.5-5.0)\n",
        "        value = np.random.uniform(2.5, 5.0)\n",
        "    elif rand < 0.90:  # %20 yÃ¼ksek (5.0-20.0)\n",
        "        value = np.random.uniform(5.0, 20.0)\n",
        "    else:  # %10 Ã§ok yÃ¼ksek (20.0+)\n",
        "        value = np.random.exponential(10.0) + 20.0\n",
        "    \n",
        "    sample_data.append(round(value, 2))\n",
        "\n",
        "# SQLite'a kaydet\n",
        "db_path = \"/content/colab_jetx_data.db\"\n",
        "for value in sample_data:\n",
        "    save_result_to_sqlite(value, db_path)\n",
        "\n",
        "print(f\"âœ… {len(sample_data)} JetX verisi oluÅŸturuldu ve kaydedildi\")\n",
        "print(f\"ğŸ“‚ VeritabanÄ±: {db_path}\")\n",
        "print(f\"ğŸ“Š Ä°statistikler:\")\n",
        "print(f\"   - Min: {min(sample_data):.2f}\")\n",
        "print(f\"   - Max: {max(sample_data):.2f}\")\n",
        "print(f\"   - Ortalama: {np.mean(sample_data):.2f}\")\n",
        "print(f\"   - Crash oranÄ± (<1.5): {sum(1 for x in sample_data if x < 1.5)/len(sample_data)*100:.1f}%\")\n",
        "\n",
        "# Global deÄŸiÅŸken olarak sakla\n",
        "SAMPLE_DATA = sample_data\n",
        "DB_PATH = db_path\n",
        "\n",
        "print(\"\\nğŸ¯ Veri model eÄŸitimi iÃ§in hazÄ±r!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "next_steps"
      },
      "source": [
        "# ğŸ¯ Sonraki AdÄ±mlar\n",
        "\n",
        "Kurulum tamamlandÄ±! ArtÄ±k model eÄŸitimi iÃ§in hazÄ±r notebook'larÄ± kullanabilirsiniz:\n",
        "\n",
        "## ğŸ“š EÄŸitim Notebook'larÄ±:\n",
        "1. **`nbeats_training.ipynb`** - N-Beats model eÄŸitimi\n",
        "2. **`tft_training.ipynb`** - TFT model eÄŸitimi  \n",
        "3. **`lstm_training.ipynb`** - LSTM model eÄŸitimi\n",
        "4. **`ensemble_training.ipynb`** - Ensemble model eÄŸitimi\n",
        "\n",
        "## ğŸš€ KullanÄ±m:\n",
        "- Her notebook'u ayrÄ± ayrÄ± Ã§alÄ±ÅŸtÄ±rabilirsiniz\n",
        "- GPU desteÄŸi otomatik aktif olacak\n",
        "- EÄŸitilmiÅŸ modeller `/content/trained_models/` dizininde saklanacak\n",
        "\n",
        "## ğŸ’¡ Ä°puÃ§larÄ±:\n",
        "- Runtime > Change runtime type > GPU seÃ§in\n",
        "- EÄŸitim sÃ¼resini takip edin (12 saat limit)\n",
        "- Ã–nemli modelleri Google Drive'a kaydedin\n",
        "\n",
        "---\n",
        "\n",
        "**ğŸ‰ BaÅŸarÄ±yla kurulum tamamlandÄ±! Model eÄŸitimine geÃ§ebilirsiniz.**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
