{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ Ä°nteraktif JetX Model EÄŸitmeni (v4.0)\n",
    "Bu not defteri, JetX tahmin sistemi iÃ§in **interaktif** ve tam otomatik bir eÄŸitim akÄ±ÅŸÄ± saÄŸlar.\n",
    "\n",
    "## âœ¨ Yeni Ã–zellikler (v4.0)\n",
    "- **Ä°nteraktif Model SeÃ§imi:** Kod yazmadan, sadece onay kutularÄ±nÄ± (checkbox) iÅŸaretleyerek eÄŸitmek istediÄŸiniz modelleri seÃ§in.\n",
    "- **Otomatik HPO & MLflow:** `Optuna` ve `MLflow` entegrasyonlarÄ± ile en iyi hiperparametreler bulunur ve tÃ¼m sÃ¼reÃ§ izlenir.\n",
    "- **KararlÄ± Ã‡alÄ±ÅŸma:** Ã–nceki sÃ¼rÃ¼mlerdeki kritik hatalar giderildi ve yeni doÄŸruluk metriÄŸi eklendi.\n",
    "\n",
    "**âš ï¸ BaÅŸlamadan Ã–nce: Runtime > Change runtime type > GPU seÃ§eneÄŸini etkinleÅŸtirin!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ› ï¸ 1. Sistem Kurulumu ve Projeyi YÃ¼kleme\n",
    "Bu hÃ¼cre, projeyi GitHub'dan klonlar (veya gÃ¼nceller) ve gerekli tÃ¼m kÃ¼tÃ¼phaneleri yÃ¼kler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def setup_environment():\n",
    "    \"\"\"Clones or updates the repository and sets up the environment.\"\"\"\n",
    "    repo_url = \"https://github.com/onndd/predictor_1.git\"\n",
    "    project_dir = \"/content/predictor_1\"\n",
    "\n",
    "    if os.path.exists(project_dir):\n",
    "        print(\"ğŸ“ Proje zaten mevcut. GÃ¼ncelleniyor...\")\n",
    "        os.chdir(project_dir)\n",
    "        subprocess.run([\"git\", \"pull\", \"origin\", \"main\"], check=True, capture_output=True)\n",
    "    else:\n",
    "        print(\"ğŸ“¥ GitHub'dan proje klonlanÄ±yor...\")\n",
    "        os.chdir(\"/content\")\n",
    "        subprocess.run([\"git\", \"clone\", repo_url], check=True, capture_output=True)\n",
    "        os.chdir(project_dir)\n",
    "\n",
    "    # Add src to Python path\n",
    "    src_path = os.path.join(project_dir, \"src\")\n",
    "    if src_path not in sys.path:\n",
    "        sys.path.insert(0, src_path)\n",
    "        print(f\"âœ… {src_path} Python path'e eklendi\")\n",
    "\n",
    "    # Install dependencies\n",
    "    requirements_path = os.path.join(project_dir, 'requirements_enhanced.txt')\n",
    "    if os.path.exists(requirements_path):\n",
    "        print(\"ğŸ“¦ Gerekli kÃ¼tÃ¼phaneler yÃ¼kleniyor...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-r\", requirements_path])\n",
    "        print(\"âœ… KÃ¼tÃ¼phaneler baÅŸarÄ±yla yÃ¼klendi.\")\n",
    "\n",
    "setup_environment()\n",
    "print(\"ğŸ‰ Kurulum tamamlandÄ±!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š 2. MLflow Deney Takibini BaÅŸlatma\n",
    "Bu hÃ¼cre, MLflow arayÃ¼zÃ¼nÃ¼ baÅŸlatÄ±r ve `ngrok` kullanarak size eriÅŸebileceÄŸiniz bir public URL verir. LÃ¼tfen aÅŸaÄŸÄ±daki hÃ¼creye ngrok authtoken'Ä±nÄ±zÄ± girin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "from colab.health_check import ColabHealthCheck\n",
    "import time\n",
    "\n",
    "# ngrok authtoken'Ä±nÄ±zÄ± buraya girin\n",
    "NGROK_AUTH_TOKEN = getpass('LÃ¼tfen ngrok authtokeninizi girin: ')\n",
    "\n",
    "# ngrok baÄŸlantÄ±sÄ±nÄ± Ã¶nceden test et\n",
    "health_checker = ColabHealthCheck()\n",
    "ngrok_ok, error_message = health_checker.check_ngrok_tunnel(NGROK_AUTH_TOKEN)\n",
    "\n",
    "if ngrok_ok:\n",
    "    print(\"âœ… ngrok baÄŸlantÄ± testi baÅŸarÄ±lÄ±.\")\n",
    "    \n",
    "    # MLflow UI'Ä± arka planda baÅŸlat\n",
    "    get_ipython().system_raw('mlflow ui --host 0.0.0.0 &')\n",
    "    \n",
    "    # Give MLflow a moment to start\n",
    "    time.sleep(5)\n",
    "    \n",
    "    print(\"\\nâœ… MLflow arayÃ¼zÃ¼ iÃ§in public URL oluÅŸturuluyor...\")\n",
    "    print(\"ğŸ‘‡ AÅŸaÄŸÄ±daki linke tÄ±klayarak deneyleri izleyebilirsiniz:\")\n",
    "    \n",
    "    try:\n",
    "        from pyngrok import ngrok\n",
    "        public_url = ngrok.connect(5000, \"http\").public_url\n",
    "        print(f\"--> {public_url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ngrok tÃ¼neli oluÅŸturulamadÄ±. Hata: {e}\")\n",
    "else:\n",
    "    print(f\"\\nâŒ ngrok Ã¶n kontrolÃ¼ baÅŸarÄ±sÄ±z oldu. LÃ¼tfen authtoken'Ä±nÄ±zÄ± ve internet baÄŸlantÄ±nÄ±zÄ± kontrol edin.\")\n",
    "    print(f\"   Hata DetayÄ±: {error_message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ 3. Modelleri SeÃ§ ve EÄŸitimi BaÅŸlat\n",
    "AÅŸaÄŸÄ±daki arayÃ¼zÃ¼ kullanarak eÄŸitmek istediÄŸiniz modelleri seÃ§in ve butona tÄ±klayarak eÄŸitimi baÅŸlatÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from src.training.master_trainer import MasterTrainer\n",
    "from src.config.settings import get_aggressive_training_profiles\n",
    "import traceback\n",
    "\n",
    "# EÄŸitilebilir modelleri al\n",
    "available_models = list(get_aggressive_training_profiles().keys())\n",
    "\n",
    "# ArayÃ¼z elemanlarÄ±nÄ± oluÅŸtur\n",
    "model_checkboxes = [widgets.Checkbox(value=False, description=model) for model in available_models]\n",
    "start_button = widgets.Button(description=\"EÄŸitimi BaÅŸlat\", button_style='success', icon='rocket')\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    with output_area:\n",
    "        output_area.clear_output()\n",
    "        selected_models = [cb.description for cb in model_checkboxes if cb.value]\n",
    "        \n",
    "        if not selected_models:\n",
    "            print(\"âš ï¸ LÃ¼tfen en az bir model seÃ§in!\")\n",
    "            return\n",
    "        \n",
    "        print(f\"ğŸš€ SeÃ§ilen modellerle eÄŸitim baÅŸlatÄ±lÄ±yor: {', '.join(selected_models)}\")\n",
    "        \n",
    "        # Cihaz tespiti\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        if device == 'cuda':\n",
    "            print(f\"âœ… GPU bulundu: {torch.cuda.get_device_name(0)}\")\n",
    "        else:\n",
    "            print(\"âš ï¸ GPU bulunamadÄ±. EÄŸitim CPU ile devam edecek.\")\n",
    "            \n",
    "        try:\n",
    "            master_trainer = MasterTrainer(models_to_train=selected_models, device=device)\n",
    "            master_trainer.run()\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ EÄŸitim sÄ±rasÄ±nda beklenmedik bir hata oluÅŸtu: {e}\")\n",
    "            traceback.print_exc()\n",
    "\n",
    "start_button.on_click(on_button_clicked)\n",
    "\n",
    "# ArayÃ¼zÃ¼ gÃ¶ster\n",
    "print(\"EÄŸitmek istediÄŸiniz modelleri seÃ§in:\")\n",
    "ui = widgets.VBox(model_checkboxes + [start_button, output_area])\n",
    "display(ui)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
