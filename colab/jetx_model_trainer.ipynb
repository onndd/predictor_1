{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ Otomatik JetX Model EÄŸitmeni\n",
    "\n",
    "Bu not defteri, mevcut tÃ¼m JetX tahmin modellerini, en iyi performans iÃ§in optimize edilmiÅŸ hiperparametrelerle otomatik olarak eÄŸitir.\n",
    "\n",
    "## âœ¨ Ã–zellikler\n",
    "- **Tam Otomatik**: Manuel mÃ¼dahale gerekmez.\n",
    "- **Optimize EdilmiÅŸ Parametreler**: Her model, yÃ¼ksek doÄŸruluk iÃ§in Ã¶nceden ayarlanmÄ±ÅŸ parametrelerle eÄŸitilir.\n",
    "- **Rolling Window EÄŸitimi**: GerÃ§ek dÃ¼nya senaryolarÄ±nÄ± simÃ¼le etmek iÃ§in rolling window yaklaÅŸÄ±mÄ± kullanÄ±lÄ±r.\n",
    "- **DetaylÄ± Raporlama**: Her modelin eÄŸitim sÃ¼reci ve sonuÃ§larÄ± net bir ÅŸekilde raporlanÄ±r."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**âš ï¸ BaÅŸlamadan Ã–nce: Runtime > Change runtime type > GPU seÃ§eneÄŸini etkinleÅŸtirin!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ› ï¸ 1. Sistem Kurulumu\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import importlib.util\n",
    "\n",
    "def check_and_install(package, import_name=None):\n",
    "    \"\"\"Paketi kontrol et ve yoksa yÃ¼kle\"\"\"\n",
    "    if import_name is None:\n",
    "        import_name = package\n",
    "    if importlib.util.find_spec(import_name) is None:\n",
    "        print(f'ğŸ“¦ {package} yÃ¼kleniyor...')\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"--quiet\"])\n",
    "    else:\n",
    "        print(f'âœ… {package} zaten yÃ¼klÃ¼.')\n",
    "\n",
    "required_packages = [(\"ipywidgets\", \"ipywidgets\"), (\"tqdm\", \"tqdm\"), (\"plotly\", \"plotly\"), (\"seaborn\", \"seaborn\")]\n",
    "for package, import_name in required_packages:\n",
    "    check_and_install(package, import_name)\n",
    "\n",
    "print(\"ğŸ‰ Kurulum tamamlandÄ±!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“š 2. Gerekli KÃ¼tÃ¼phanelerin ve Projenin YÃ¼klenmesi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def clone_or_update_repo():\n",
    "    \"\"\"Repository'yi klonla veya gÃ¼ncelle\"\"\"\n",
    "    repo_url = \"https://github.com/onndd/predictor_1.git\"\n",
    "    project_dir = \"/content/predictor_1\"\n",
    "    if os.path.exists(project_dir):\n",
    "        print(\"ğŸ“ Proje zaten mevcut. GÃ¼ncelleniyor...\")\n",
    "        os.chdir(project_dir)\n",
    "        subprocess.run([\"git\", \"pull\", \"origin\", \"main\"], check=True, capture_output=True)\n",
    "    else:\n",
    "        print(\"ğŸ“¥ GitHub'dan proje klonlanÄ±yor...\")\n",
    "        os.chdir(\"/content\")\n",
    "        subprocess.run([\"git\", \"clone\", repo_url], check=True, capture_output=True)\n",
    "        os.chdir(project_dir)\n",
    "    \n",
    "    src_path = os.path.join(project_dir, \"src\")\n",
    "    if src_path not in sys.path:\n",
    "        sys.path.insert(0, src_path)\n",
    "        print(f\"âœ… {src_path} Python path'e eklendi\")\n",
    "    return project_dir\n",
    "\n",
    "try:\n",
    "    PROJECT_DIR = clone_or_update_repo()\n",
    "    models_dir = \"/content/trained_models\"\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    print(f\"ğŸ’¾ Model dizini hazÄ±r: {models_dir}\")\n",
    "    print(\"ğŸ‰ Repository kurulumu tamamlandÄ±!\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Repository kurulum hatasÄ±: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š 3. Veri YÃ¼kleme ve HazÄ±rlama\n",
    "from data_processing.loader import load_data_from_sqlite\n",
    "\n",
    "def load_real_jetx_data():\n",
    "    repo_db_path = \"/content/predictor_1/data/jetx_data.db\"\n",
    "    if os.path.exists(repo_db_path):\n",
    "        data = load_data_from_sqlite(repo_db_path)\n",
    "        if data and len(data) > 1000:\n",
    "            print(f\"âœ… Repository'den {len(data)} kayÄ±t yÃ¼klendi\")\n",
    "            return data\n",
    "    print(\"âš ï¸ GerÃ§ek veri bulunamadÄ±!\")\n",
    "    return None\n",
    "\n",
    "def create_rolling_chunks(data, chunk_size=1000):\n",
    "    chunks = []\n",
    "    for i in range(0, len(data), chunk_size):\n",
    "        chunk = data[i:i + chunk_size]\n",
    "        if len(chunk) >= chunk_size:\n",
    "            chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "print(\"ğŸ“Š GerÃ§ek JetX verisi yÃ¼kleniyor...\")\n",
    "jetx_data = load_real_jetx_data()\n",
    "if jetx_data:\n",
    "    ROLLING_CHUNKS = create_rolling_chunks(jetx_data, 1000)\n",
    "    print(f\"ğŸ“Š Rolling window chunks: {len(ROLLING_CHUNKS)} adet (her biri 1000 kayÄ±t)\")\n",
    "    print(\"ğŸ¯ Veri hazÄ±rlama tamamlandÄ±!\")\n",
    "else:\n",
    "    print(\"âŒ Veri hazÄ±rlama baÅŸarÄ±sÄ±z!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ—ï¸ 4. EÄŸitim Sisteminin YÃ¼klenmesi\n",
    "exec(open('/content/predictor_1/colab/rolling_training_system.py').read())\n",
    "exec(open('/content/predictor_1/colab/rolling_integration.py').read())\n",
    "\n",
    "model_registry = ModelRegistry()\n",
    "print(\"âœ… Rolling Window EÄŸitim Sistemi ve Model KayÄ±tÃ§Ä±sÄ± hazÄ±r!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ 5. Otomatik EÄŸitim ve Raporlama\n",
    "import traceback\n",
    "\n",
    "OPTIMIZED_PARAMS = {\n",
    "    'N-Beats': {\n",
    "        'sequence_length': 200,\n",
    "        'hidden_size': 512,\n",
    "        'num_stacks': 4,\n",
    "        'num_blocks': 4,\n",
    "        'learning_rate': 0.0005,\n",
    "        'epochs_per_cycle': 50,\n",
    "        'batch_size': 32,\n",
    "        'threshold': 1.5,\n",
    "        'crash_weight': 2.5\n",
    "    },\n",
    "    'TFT': {\n",
    "        'sequence_length': 200,\n",
    "        'hidden_size': 256,\n",
    "        'num_heads': 4,\n",
    "        'num_layers': 3,\n",
    "        'learning_rate': 0.0005,\n",
    "        'epochs_per_cycle': 40,\n",
    "        'batch_size': 16,\n",
    "        'threshold': 1.5,\n",
    "        'crash_weight': 2.5\n",
    "    },\n",
    "    'LSTM': {\n",
    "        'sequence_length': 150,\n",
    "        'lstm_units': 256,\n",
    "        'dropout_rate': 0.3,\n",
    "        'learning_rate': 0.0005,\n",
    "        'epochs_per_cycle': 60,\n",
    "        'batch_size': 32,\n",
    "        'threshold': 1.5,\n",
    "        'crash_weight': 2.5\n",
    "    }\n",
    "}\n",
    "\n",
    "def run_automated_training(model_registry, rolling_chunks):\n",
    "    print(\"ğŸš€ BAÅLATILIYOR: Otomatik Model EÄŸitimi\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    models_to_train = ['N-Beats', 'TFT', 'LSTM']\n",
    "    \n",
    "    for model_name in models_to_train:\n",
    "        print(f\"\\n\\n--- {model_name} EÄÄ°TÄ°MÄ° BAÅLIYOR ---\")\n",
    "        params = OPTIMIZED_PARAMS[model_name]\n",
    "        print(\"âš™ï¸ KullanÄ±lan Parametreler:\")\n",
    "        for key, value in params.items():\n",
    "            print(f\"   - {key}: {value}\")\n",
    "        \n",
    "        try:\n",
    "            trainer = RollingWindowTrainer(model_registry, rolling_chunks)\n",
    "            trainer.start_rolling_training(\n",
    "                model_type=model_name,\n",
    "                sequence_length=params['sequence_length'],\n",
    "                hidden_size=params.get('hidden_size', params.get('lstm_units')),\n",
    "                num_stacks=params.get('num_stacks'),\n",
    "                num_blocks=params.get('num_blocks'),\n",
    "                num_heads=params.get('num_heads'),\n",
    "                num_layers=params.get('num_layers'),\n",
    "                dropout_rate=params.get('dropout_rate'),\n",
    "                learning_rate=params['learning_rate'],\n",
    "                epochs_per_cycle=params['epochs_per_cycle'],\n",
    "                batch_size=params['batch_size'],\n",
    "                threshold=params['threshold'],\n",
    "                crash_weight=params['crash_weight']\n",
    "            )\n",
    "            print(f\"âœ… {model_name} eÄŸitimi baÅŸarÄ±yla tamamlandÄ±.\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ {model_name} eÄŸitimi sÄ±rasÄ±nda bir hata oluÅŸtu: {e}\")\n",
    "            traceback.print_exc()\n",
    "        print(f\"--- {model_name} EÄÄ°TÄ°MÄ° BÄ°TTÄ° ---\")\n",
    "\n",
    "    print(\"\\n\\nğŸ‰ TÃœM MODELLERÄ°N EÄÄ°TÄ°MÄ° TAMAMLANDI ğŸ‰\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\\nğŸ“Š EÄÄ°TÄ°M SONUÃ‡LARI Ã–ZETÄ°:\")\n",
    "    analyze_training_results()\n",
    "\n",
    "if 'ROLLING_CHUNKS' in globals() and 'model_registry' in globals() and ROLLING_CHUNKS:\n",
    "    run_automated_training(model_registry, ROLLING_CHUNKS)\n",
    "else:\n",
    "    print(\"âŒ Otomatik eÄŸitim baÅŸlatÄ±lamadÄ±. Veri yÃ¼kleme adÄ±mÄ±nÄ±n baÅŸarÄ±lÄ± olduÄŸundan emin olun.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Automated_JetX_Trainer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
