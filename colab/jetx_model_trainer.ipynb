{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚀 Tam Otomatik JetX Model Eğitmeni (v3.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu not defteri, JetX tahmin sistemi için yeniden yapılandırılmış ve tam otomatik bir eğitim akışı sağlar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✨ Yeni Özellikler (v3.2)\n",
    "\n",
    "- **ngrok Ön Kontrolü:** `ngrok` tüneli oluşturulmadan önce bağlantı ve `authtoken` test edilir, olası hatalar en başta tespit edilir.\n",
    "- **Otomatik Hiperparametre Optimizasyonu (HPO):** `Optuna` entegrasyonu ile her model için en iyi hiperparametreler otomatik olarak bulunur.\n",
    "- **Deney Takibi:** `MLflow` entegrasyonu ile tüm eğitim süreçleri, metrikler ve modeller kaydedilir ve izlenebilir.\n",
    "- **Merkezi Yapılandırma:** Tüm ayarlar artık proje kök dizinindeki `config.yaml` dosyasından yönetilir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**⚠️ Başlamadan Önce: Runtime > Change runtime type > GPU seçeneğini etkinleştirin!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🛠️ 1. Sistem Kurulumu ve Projeyi Yükleme"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "setup_system"
   },
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def setup_environment():\n",
    "    \"\"\"Clones or updates the repository and sets up the environment.\"\"\"\n",
    "    repo_url = \"https://github.com/onndd/predictor_1.git\"\n",
    "    project_dir = \"/content/predictor_1\"\n",
    "\n",
    "    if os.path.exists(project_dir):\n",
    "        print(\"📁 Proje zaten mevcut. Güncelleniyor...\")\n",
    "        os.chdir(project_dir)\n",
    "        subprocess.run([\"git\", \"pull\", \"origin\", \"main\"], check=True, capture_output=True)\n",
    "    else:\n",
    "        print(\"📥 GitHub'dan proje klonlanıyor...\")\n",
    "        os.chdir(\"/content\")\n",
    "        subprocess.run([\"git\", \"clone\", repo_url], check=True, capture_output=True)\n",
    "        os.chdir(project_dir)\n",
    "\n",
    "    # Add src to Python path\n",
    "    src_path = os.path.join(project_dir, \"src\")\n",
    "    if src_path not in sys.path:\n",
    "        sys.path.insert(0, src_path)\n",
    "        print(f\"✅ {src_path} Python path'e eklendi\")\n",
    "\n",
    "    # Install dependencies\n",
    "    requirements_path = os.path.join(project_dir, 'requirements_enhanced.txt')\n",
    "    if os.path.exists(requirements_path):\n",
    "        print(\"📦 Gerekli kütüphaneler yükleniyor...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", requirements_path])\n",
    "        print(\"✅ Kütüphaneler başarıyla yüklendi.\")\n",
    "\n",
    "setup_environment()\n",
    "print(\"🎉 Kurulum tamamlandı!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 2. MLflow Deney Takibini Başlatma\n",
    "\n",
    "Bu hücre, MLflow arayüzünü başlatır ve `ngrok` kullanarak size erişebileceğiniz bir public URL verir. **Lütfen aşağıdaki hücreye ngrok authtoken'ınızı girin.**\n",
    "\n",
    "1. [ngrok Dashboard](https://dashboard.ngrok.com/get-started/your-authtoken) adresine gidin.\n",
    "2. Authtoken'ınızı kopyalayın.\n",
    "3. Aşağıdaki `NGROK_AUTH_TOKEN` değişkenine yapıştırın."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "start_mlflow"
   },
   "source": [
    "from getpass import getpass\n",
    "from colab.health_check import ColabHealthCheck\n",
    "import time\n",
    "\n",
    "# ngrok authtoken'ınızı buraya girin\n",
    "NGROK_AUTH_TOKEN = getpass('Lütfen ngrok authtokeninizi girin: ')\n",
    "\n",
    "# ngrok bağlantısını önceden test et\n",
    "health_checker = ColabHealthCheck()\n",
    "ngrok_ok, error_message = health_checker.check_ngrok_tunnel(NGROK_AUTH_TOKEN)\n",
    "\n",
    "if ngrok_ok:\n",
    "    print(\"✅ ngrok bağlantı testi başarılı.\")\n",
    "    \n",
    "    # MLflow UI'ı arka planda başlat\n",
    "    get_ipython().system_raw('mlflow ui --host 0.0.0.0 &')\n",
    "    \n",
    "    # Give MLflow a moment to start\n",
    "    time.sleep(5)\n",
    "    \n",
    "    print(\"\\n✅ MLflow arayüzü için public URL oluşturuluyor...\")\n",
    "    print(\"👇 Aşağıdaki linke tıklayarak deneyleri izleyebilirsiniz:\")\n",
    "    \n",
    "    try:\n",
    "        from pyngrok import ngrok\n",
    "        # Connect to the MLflow UI port and print only the public URL\n",
    "        public_url = ngrok.connect(5000, \"http\").public_url\n",
    "        print(f\"--> {public_url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ ngrok tüneli oluşturulamadı. Hata: {e}\")\n",
    "else:\n",
    "    print(f\"\\n❌ ngrok ön kontrolü başarısız oldu. Lütfen authtoken'ınızı ve internet bağlantınızı kontrol edin.\")\n",
    "    print(f\"   Hata Detayı: {error_message}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 3. Otomatik Eğitim Sürecini Başlatma"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "run_training"
   },
   "source": [
    "import torch\n",
    "from src.training.master_trainer import MasterTrainer\n",
    "import traceback\n",
    "\n",
    "# Cihaz tespiti (GPU veya CPU)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device == 'cuda':\n",
    "    print(f\"✅ GPU bulundu: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"⚠️ GPU bulunamadı. Eğitim CPU ile devam edecek.\")\n",
    "\n",
    "try:\n",
    "    # MasterTrainer'ı başlat ve tüm eğitim sürecini çalıştır.\n",
    "    master_trainer = MasterTrainer(models_to_train=['N-Beats', 'TFT', 'LSTM'], device=device)\n",
    "    master_trainer.run()\n",
    "except Exception as e:\n",
    "    print(f\"❌ Eğitim sırasında beklenmedik bir hata oluştu: {e}\")\n",
    "    traceback.print_exc()"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
