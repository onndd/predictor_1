{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbeats_header"
      },
      "source": [
        "# 🧠 N-Beats Model Eğitimi - Google Colab\n",
        "\n",
        "Bu notebook N-Beats (Neural Basis Expansion Analysis for Time Series) modelini JetX verileri üzerinde eğitir.\n",
        "\n",
        "## 📋 N-Beats Özellikleri:\n",
        "- **Interpretable**: Trend ve seasonality ayrıştırması\n",
        "- **JetX Optimized**: Crash/pump pattern detection\n",
        "- **GPU Accelerated**: PyTorch CUDA desteği\n",
        "- **Multi-output**: Value, probability, confidence\n",
        "\n",
        "---\n",
        "\n",
        "**⚠️ Önce `colab_setup.ipynb` notebook'unu çalıştırın!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbeats_setup"
      },
      "outputs": [],
      "source": [
        "# 🔧 Kurulum ve Import'lar\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# Proje path'i ekle\n",
        "sys.path.insert(0, '/content/predictor_1/src')\n",
        "\n",
        "# Model import'ları\n",
        "from models.deep_learning.n_beats.n_beats_model import NBeatsPredictor\n",
        "from data_processing.loader import load_data_from_sqlite\n",
        "from data_processing.splitter import create_sequences\n",
        "\n",
        "# GPU kontrolü\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"🎯 Device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"📱 GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"💾 GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "\n",
        "# Matplotlib için stil\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"✅ N-Beats kurulumu tamamlandı!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_data"
      },
      "outputs": [],
      "source": [
        "# 📊 Veri Yükleme\n",
        "print(\"📊 JETX VERİSİ YÜKLEME\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Colab'dan veritabanını yükle\n",
        "db_path = \"/content/colab_jetx_data.db\"\n",
        "df = load_data_from_sqlite(db_path)\n",
        "\n",
        "# Veriyi liste formatına çevir\n",
        "jetx_data = [row[1] for row in df.data]  # value column\n",
        "print(f\"✅ {len(jetx_data)} JetX verisi yüklendi\")\n",
        "\n",
        "# Veri analizi\n",
        "jetx_array = np.array(jetx_data)\n",
        "print(f\"📈 İstatistikler:\")\n",
        "print(f\"   - Min: {jetx_array.min():.2f}\")\n",
        "print(f\"   - Max: {jetx_array.max():.2f}\")\n",
        "print(f\"   - Mean: {jetx_array.mean():.2f}\")\n",
        "print(f\"   - Std: {jetx_array.std():.2f}\")\n",
        "print(f\"   - Crash rate (<1.5): {(jetx_array < 1.5).mean()*100:.1f}%\")\n",
        "\n",
        "# Veri görselleştirmesi\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Time series plot\n",
        "axes[0,0].plot(jetx_data[:200])\n",
        "axes[0,0].set_title('İlk 200 JetX Değeri')\n",
        "axes[0,0].set_xlabel('Zaman')\n",
        "axes[0,0].set_ylabel('JetX Değeri')\n",
        "axes[0,0].axhline(y=1.5, color='r', linestyle='--', alpha=0.7, label='Threshold')\n",
        "axes[0,0].legend()\n",
        "\n",
        "# Histogram\n",
        "axes[0,1].hist(jetx_data, bins=50, alpha=0.7, edgecolor='black')\n",
        "axes[0,1].set_title('JetX Değer Dağılımı')\n",
        "axes[0,1].set_xlabel('JetX Değeri')\n",
        "axes[0,1].set_ylabel('Frekans')\n",
        "axes[0,1].axvline(x=1.5, color='r', linestyle='--', alpha=0.7, label='Threshold')\n",
        "axes[0,1].legend()\n",
        "\n",
        "# Box plot\n",
        "axes[1,0].boxplot(jetx_data)\n",
        "axes[1,0].set_title('JetX Değer Box Plot')\n",
        "axes[1,0].set_ylabel('JetX Değeri')\n",
        "\n",
        "# Autocorrelation\n",
        "lags = range(1, min(50, len(jetx_data)//10))\n",
        "autocorr = [np.corrcoef(jetx_data[:-lag], jetx_data[lag:])[0,1] for lag in lags]\n",
        "axes[1,1].plot(lags, autocorr)\n",
        "axes[1,1].set_title('Autocorrelation')\n",
        "axes[1,1].set_xlabel('Lag')\n",
        "axes[1,1].set_ylabel('Correlation')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"🎯 Veri analizi tamamlandı!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prepare_data"
      },
      "outputs": [],
      "source": [
        "# 🔧 Veri Hazırlama\n",
        "print(\"🔧 N-BEATS İÇİN VERİ HAZIRLAMA\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# N-Beats için parametreler\n",
        "SEQUENCE_LENGTH = 100  # Daha kısa sequence GPU memory için\n",
        "TRAIN_SPLIT = 0.8\n",
        "VALIDATION_SPLIT = 0.1\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Veriyi train/val/test olarak böl\n",
        "n_train = int(len(jetx_data) * TRAIN_SPLIT)\n",
        "n_val = int(len(jetx_data) * VALIDATION_SPLIT)\n",
        "\n",
        "train_data = jetx_data[:n_train]\n",
        "val_data = jetx_data[n_train:n_train + n_val]\n",
        "test_data = jetx_data[n_train + n_val:]\n",
        "\n",
        "print(f\"📊 Veri bölümü:\")\n",
        "print(f\"   - Train: {len(train_data)} samples\")\n",
        "print(f\"   - Validation: {len(val_data)} samples\")\n",
        "print(f\"   - Test: {len(test_data)} samples\")\n",
        "\n",
        "# Normalizasyon (optional)\n",
        "train_mean = np.mean(train_data)\n",
        "train_std = np.std(train_data)\n",
        "print(f\"📏 Normalizasyon parametreleri:\")\n",
        "print(f\"   - Mean: {train_mean:.3f}\")\n",
        "print(f\"   - Std: {train_std:.3f}\")\n",
        "\n",
        "print(\"✅ Veri hazırlandı!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_model"
      },
      "outputs": [],
      "source": [
        "# 🧠 N-Beats Model Oluşturma\n",
        "print(\"🧠 N-BEATS MODEL OLUŞTURMA\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Model parametreleri\n",
        "model_params = {\n",
        "    'sequence_length': SEQUENCE_LENGTH,\n",
        "    'hidden_size': 256,  # GPU memory için optimize\n",
        "    'num_stacks': 3,\n",
        "    'num_blocks': 2,  # Daha az block GPU memory için\n",
        "    'learning_rate': 0.001,\n",
        "    'threshold': 1.5,\n",
        "    'crash_weight': 2.0\n",
        "}\n",
        "\n",
        "print(f\"🔧 Model parametreleri:\")\n",
        "for key, value in model_params.items():\n",
        "    print(f\"   - {key}: {value}\")\n",
        "\n",
        "# Model oluştur\n",
        "nbeats_model = NBeatsPredictor(**model_params)\n",
        "\n",
        "# GPU'ya taşı\n",
        "if torch.cuda.is_available():\n",
        "    nbeats_model.model = nbeats_model.model.cuda()\n",
        "    print(\"✅ Model GPU'ya taşındı\")\n",
        "\n",
        "# Model özeti\n",
        "total_params = sum(p.numel() for p in nbeats_model.model.parameters())\n",
        "trainable_params = sum(p.numel() for p in nbeats_model.model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"📊 Model istatistikleri:\")\n",
        "print(f\"   - Total parameters: {total_params:,}\")\n",
        "print(f\"   - Trainable parameters: {trainable_params:,}\")\n",
        "print(f\"   - Model size: ~{total_params * 4 / 1024**2:.1f} MB\")\n",
        "\n",
        "print(\"✅ N-Beats model hazır!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_model"
      },
      "outputs": [],
      "source": [
        "# 🚀 Model Eğitimi\n",
        "print(\"🚀 N-BEATS MODEL EĞİTİMİ\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Eğitim parametreleri\n",
        "EPOCHS = 50  # Colab zaman limiti için\n",
        "VERBOSE = True\n",
        "\n",
        "print(f\"🎯 Eğitim başlıyor...\")\n",
        "print(f\"   - Epochs: {EPOCHS}\")\n",
        "print(f\"   - Batch size: {BATCH_SIZE}\")\n",
        "print(f\"   - Device: {device}\")\n",
        "\n",
        "# Eğitim başlangıç zamanı\n",
        "start_time = time.time()\n",
        "\n",
        "# Model eğitimi\n",
        "try:\n",
        "    history = nbeats_model.train(\n",
        "        data=train_data,\n",
        "        epochs=EPOCHS,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        validation_split=0.2,\n",
        "        verbose=VERBOSE\n",
        "    )\n",
        "    \n",
        "    # Eğitim süresi\n",
        "    training_time = time.time() - start_time\n",
        "    print(f\"\\n⏱️ Eğitim süresi: {training_time/60:.2f} dakika\")\n",
        "    \n",
        "    # Eğitim sonuçları\n",
        "    final_train_loss = history['train_losses'][-1]\n",
        "    final_val_loss = history['val_losses'][-1]\n",
        "    \n",
        "    print(f\"📊 Final sonuçlar:\")\n",
        "    print(f\"   - Train Loss: {final_train_loss:.6f}\")\n",
        "    print(f\"   - Val Loss: {final_val_loss:.6f}\")\n",
        "    print(f\"   - Epochs completed: {len(history['train_losses'])}\")\n",
        "    \n",
        "    print(\"✅ Model eğitimi tamamlandı!\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"❌ Eğitim hatası: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plot_training"
      },
      "outputs": [],
      "source": [
        "# 📈 Eğitim Sonuçları Görselleştirme\n",
        "if 'history' in locals() and history:\n",
        "    print(\"📈 EĞİTİM SONUÇLARI GÖRSELLEŞTİRME\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    \n",
        "    # Loss curves\n",
        "    epochs_range = range(1, len(history['train_losses']) + 1)\n",
        "    \n",
        "    axes[0,0].plot(epochs_range, history['train_losses'], 'b-', label='Training Loss')\n",
        "    axes[0,0].plot(epochs_range, history['val_losses'], 'r-', label='Validation Loss')\n",
        "    axes[0,0].set_title('Model Loss')\n",
        "    axes[0,0].set_xlabel('Epochs')\n",
        "    axes[0,0].set_ylabel('Loss')\n",
        "    axes[0,0].legend()\n",
        "    axes[0,0].grid(True)\n",
        "    \n",
        "    # Loss zoom (son %20)\n",
        "    start_idx = max(0, int(len(history['train_losses']) * 0.8))\n",
        "    axes[0,1].plot(epochs_range[start_idx:], history['train_losses'][start_idx:], 'b-', label='Training Loss')\n",
        "    axes[0,1].plot(epochs_range[start_idx:], history['val_losses'][start_idx:], 'r-', label='Validation Loss')\n",
        "    axes[0,1].set_title('Model Loss (Son %20)')\n",
        "    axes[0,1].set_xlabel('Epochs')\n",
        "    axes[0,1].set_ylabel('Loss')\n",
        "    axes[0,1].legend()\n",
        "    axes[0,1].grid(True)\n",
        "    \n",
        "    # Learning rate curve (eğer var ise)\n",
        "    axes[1,0].plot(epochs_range, history['train_losses'], 'g-')\n",
        "    axes[1,0].set_title('Training Loss Trend')\n",
        "    axes[1,0].set_xlabel('Epochs')\n",
        "    axes[1,0].set_ylabel('Loss')\n",
        "    axes[1,0].grid(True)\n",
        "    \n",
        "    # Loss statistics\n",
        "    loss_stats = {\n",
        "        'Min Train Loss': min(history['train_losses']),\n",
        "        'Min Val Loss': min(history['val_losses']),\n",
        "        'Final Train Loss': history['train_losses'][-1],\n",
        "        'Final Val Loss': history['val_losses'][-1]\n",
        "    }\n",
        "    \n",
        "    axes[1,1].axis('off')\n",
        "    table_data = [[k, f\"{v:.6f}\"] for k, v in loss_stats.items()]\n",
        "    table = axes[1,1].table(cellText=table_data, colLabels=['Metric', 'Value'], loc='center')\n",
        "    table.auto_set_font_size(False)\n",
        "    table.set_fontsize(10)\n",
        "    table.scale(1.2, 1.5)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"✅ Eğitim sonuçları görselleştirildi!\")\n",
        "else:\n",
        "    print(\"⚠️ Eğitim history bulunamadı.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test_model"
      },
      "outputs": [],
      "source": [
        "# 🧪 Model Test ve Değerlendirme\n",
        "print(\"🧪 MODEL TEST VE DEĞERLENDİRME\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Test verisi üzerinde tahminler\n",
        "test_predictions = []\n",
        "test_actuals = []\n",
        "test_probabilities = []\n",
        "test_confidences = []\n",
        "\n",
        "print(\"🔍 Test verisi üzerinde tahminler yapılıyor...\")\n",
        "\n",
        "for i in tqdm(range(len(test_data) - SEQUENCE_LENGTH)):\n",
        "    # Sequence hazırla\n",
        "    sequence = test_data[i:i + SEQUENCE_LENGTH]\n",
        "    actual = test_data[i + SEQUENCE_LENGTH]\n",
        "    \n",
        "    try:\n",
        "        # Tahmin yap\n",
        "        predicted_value, probability, confidence = nbeats_model.predict(sequence)\n",
        "        \n",
        "        test_predictions.append(predicted_value)\n",
        "        test_actuals.append(actual)\n",
        "        test_probabilities.append(probability)\n",
        "        test_confidences.append(confidence)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Tahmin hatası: {e}\")\n",
        "        break\n",
        "\n",
        "print(f\"✅ {len(test_predictions)} tahmin yapıldı\")\n",
        "\n",
        "# Metrikleri hesapla\n",
        "if test_predictions:\n",
        "    test_predictions = np.array(test_predictions)\n",
        "    test_actuals = np.array(test_actuals)\n",
        "    test_probabilities = np.array(test_probabilities)\n",
        "    test_confidences = np.array(test_confidences)\n",
        "    \n",
        "    # Regression metrikleri\n",
        "    mae = np.mean(np.abs(test_predictions - test_actuals))\n",
        "    mse = np.mean((test_predictions - test_actuals) ** 2)\n",
        "    rmse = np.sqrt(mse)\n",
        "    \n",
        "    # Classification metrikleri (threshold = 1.5)\n",
        "    actual_binary = (test_actuals >= 1.5).astype(int)\n",
        "    pred_binary = (test_probabilities >= 0.5).astype(int)\n",
        "    \n",
        "    accuracy = np.mean(actual_binary == pred_binary)\n",
        "    precision = np.sum((pred_binary == 1) & (actual_binary == 1)) / np.sum(pred_binary == 1) if np.sum(pred_binary == 1) > 0 else 0\n",
        "    recall = np.sum((pred_binary == 1) & (actual_binary == 1)) / np.sum(actual_binary == 1) if np.sum(actual_binary == 1) > 0 else 0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    \n",
        "    print(f\"📊 TEST SONUÇLARI:\")\n",
        "    print(f\"   Regression Metrics:\")\n",
        "    print(f\"   - MAE: {mae:.4f}\")\n",
        "    print(f\"   - RMSE: {rmse:.4f}\")\n",
        "    print(f\"   Classification Metrics:\")\n",
        "    print(f\"   - Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"   - Precision: {precision:.4f}\")\n",
        "    print(f\"   - Recall: {recall:.4f}\")\n",
        "    print(f\"   - F1-Score: {f1:.4f}\")\n",
        "    print(f\"   Confidence:\")\n",
        "    print(f\"   - Mean Confidence: {np.mean(test_confidences):.4f}\")\n",
        "    print(f\"   - Std Confidence: {np.std(test_confidences):.4f}\")\n",
        "\n",
        "print(\"✅ Model değerlendirmesi tamamlandı!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plot_predictions"
      },
      "outputs": [],
      "source": [
        "# 📊 Tahmin Sonuçları Görselleştirme\n",
        "if 'test_predictions' in locals() and len(test_predictions) > 0:\n",
        "    print(\"📊 TAHMİN SONUÇLARI GÖRSELLEŞTİRME\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    \n",
        "    # Actual vs Predicted\n",
        "    axes[0,0].scatter(test_actuals, test_predictions, alpha=0.6)\n",
        "    axes[0,0].plot([test_actuals.min(), test_actuals.max()], [test_actuals.min(), test_actuals.max()], 'r--', alpha=0.8)\n",
        "    axes[0,0].set_xlabel('Actual Values')\n",
        "    axes[0,0].set_ylabel('Predicted Values')\n",
        "    axes[0,0].set_title('Actual vs Predicted')\n",
        "    axes[0,0].grid(True)\n",
        "    \n",
        "    # Time series comparison (ilk 100 tahmin)\n",
        "    n_show = min(100, len(test_predictions))\n",
        "    x_axis = range(n_show)\n",
        "    axes[0,1].plot(x_axis, test_actuals[:n_show], 'b-', label='Actual', alpha=0.7)\n",
        "    axes[0,1].plot(x_axis, test_predictions[:n_show], 'r-', label='Predicted', alpha=0.7)\n",
        "    axes[0,1].axhline(y=1.5, color='g', linestyle='--', alpha=0.5, label='Threshold')\n",
        "    axes[0,1].set_xlabel('Time Steps')\n",
        "    axes[0,1].set_ylabel('JetX Value')\n",
        "    axes[0,1].set_title(f'Time Series Comparison (İlk {n_show} tahmin)')\n",
        "    axes[0,1].legend()\n",
        "    axes[0,1].grid(True)\n",
        "    \n",
        "    # Error distribution\n",
        "    errors = test_predictions - test_actuals\n",
        "    axes[1,0].hist(errors, bins=30, alpha=0.7, edgecolor='black')\n",
        "    axes[1,0].axvline(x=0, color='r', linestyle='--', alpha=0.7)\n",
        "    axes[1,0].set_xlabel('Prediction Error')\n",
        "    axes[1,0].set_ylabel('Frequency')\n",
        "    axes[1,0].set_title('Error Distribution')\n",
        "    axes[1,0].grid(True)\n",
        "    \n",
        "    # Confidence vs Error\n",
        "    axes[1,1].scatter(test_confidences, np.abs(errors), alpha=0.6)\n",
        "    axes[1,1].set_xlabel('Confidence')\n",
        "    axes[1,1].set_ylabel('Absolute Error')\n",
        "    axes[1,1].set_title('Confidence vs Absolute Error')\n",
        "    axes[1,1].grid(True)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"✅ Tahmin sonuçları görselleştirildi!\")\n",
        "else:\n",
        "    print(\"⚠️ Tahmin sonuçları bulunamadı.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "save_model"
      },
      "outputs": [],
      "source": [
        "# 💾 Model Kaydetme\n",
        "print(\"💾 MODEL KAYDETME\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Model kaydetme dizini\n",
        "model_dir = \"/content/trained_models/\"\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "# Model dosya adı\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "model_filename = f\"nbeats_model_{timestamp}.pth\"\n",
        "model_path = os.path.join(model_dir, model_filename)\n",
        "\n",
        "# Model kaydet\n",
        "try:\n",
        "    nbeats_model.save_model(model_path)\n",
        "    print(f\"✅ Model kaydedildi: {model_path}\")\n",
        "    \n",
        "    # Model bilgilerini kaydet\n",
        "    model_info = {\n",
        "        'model_type': 'N-Beats',\n",
        "        'timestamp': timestamp,\n",
        "        'parameters': model_params,\n",
        "        'training_time': f\"{training_time/60:.2f} minutes\" if 'training_time' in locals() else 'Unknown',\n",
        "        'final_losses': {\n",
        "            'train': history['train_losses'][-1] if 'history' in locals() else 'Unknown',\n",
        "            'val': history['val_losses'][-1] if 'history' in locals() else 'Unknown'\n",
        "        },\n",
        "        'test_metrics': {\n",
        "            'mae': mae if 'mae' in locals() else 'Unknown',\n",
        "            'rmse': rmse if 'rmse' in locals() else 'Unknown',\n",
        "            'accuracy': accuracy if 'accuracy' in locals() else 'Unknown',\n",
        "            'f1_score': f1 if 'f1' in locals() else 'Unknown'\n",
        "        },\n",
        "        'data_info': {\n",
        "            'sequence_length': SEQUENCE_LENGTH,\n",
        "            'train_size': len(train_data),\n",
        "            'val_size': len(val_data),\n",
        "            'test_size': len(test_data)\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    # Model bilgilerini JSON olarak kaydet\n",
        "    import json\n",
        "    info_filename = f\"nbeats_info_{timestamp}.json\"\n",
        "    info_path = os.path.join(model_dir, info_filename)\n",
        "    \n",
        "    with open(info_path, 'w') as f:\n",
        "        json.dump(model_info, f, indent=2)\n",
        "    \n",
        "    print(f\"✅ Model bilgileri kaydedildi: {info_path}\")\n",
        "    \n",
        "    # Google Drive'a kopyala (optional)\n",
        "    print(\"\\n💡 Google Drive'a kaydetmek için:\")\n",
        "    print(f\"   !cp {model_path} /content/drive/MyDrive/\")\n",
        "    print(f\"   !cp {info_path} /content/drive/MyDrive/\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"❌ Model kaydetme hatası: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"\\n🎉 N-Beats model eğitimi tamamlandı!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbeats_summary"
      },
      "source": [
        "# 🎯 N-Beats Eğitimi Özeti\n",
        "\n",
        "## ✅ Tamamlanan İşlemler:\n",
        "1. **Veri Hazırlama** - JetX verisi yüklendi ve işlendi\n",
        "2. **Model Oluşturma** - N-Beats modeli GPU'da oluşturuldu\n",
        "3. **Eğitim** - Model JetX verisi üzerinde eğitildi\n",
        "4. **Değerlendirme** - Test verisi üzerinde performans ölçüldü\n",
        "5. **Görselleştirme** - Eğitim ve test sonuçları görselleştirildi\n",
        "6. **Kaydetme** - Model ve bilgiler kaydedildi\n",
        "\n",
        "## 📊 Model Özellikleri:\n",
        "- **Architecture**: Neural Basis Expansion Analysis\n",
        "- **Input**: JetX değer dizileri\n",
        "- **Output**: Değer, olasılık, güven skoru\n",
        "- **Optimization**: JetX crash/pump pattern detection\n",
        "- **Device**: GPU accelerated\n",
        "\n",
        "## 🚀 Sonraki Adımlar:\n",
        "1. **Diğer Modeller** - TFT, LSTM, Ensemble eğitimi\n",
        "2. **Hyperparameter Tuning** - Optuna ile optimizasyon\n",
        "3. **Production Deployment** - Model serving\n",
        "4. **Real-time Testing** - Canlı veri testi\n",
        "\n",
        "---\n",
        "\n",
        "**🎉 N-Beats eğitimi başarıyla tamamlandı!**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
